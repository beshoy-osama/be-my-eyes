# ğŸŒŸ Be-My-Eyes: Object Detection API

A powerful object detection system designed to assist visually impaired users with detailed image descriptions.

## ğŸ“Œ Overview

**Be-My-Eyes** is an API that combines multiple AI technologies to provide detailed descriptions of images for visually impaired users:

- ğŸ–¼ï¸ **YOLO Model**: Detects objects in images with confidence scores
- ğŸ—£ï¸ **Llama Vision (OpenRouter)**: Generates accessibility-focused captions
- ğŸ”Š **gTTS**: Converts captions to speech for audio output

The system follows a clean **MVC architecture** with proper separation of concerns.

## âœ¨ Key Features

- ğŸ—£ï¸ **Accessibility-focused descriptions**: Natural language descriptions designed for visually impaired users
- ğŸ”Š **Text-to-Speech**: Converts captions to audio files for easier consumption
- ğŸ“Š **Detailed object detection**: Identifies objects with positions (left/center/right) and confidence scores
- ğŸ”’ **Secure file handling**: Validates file types and manages temporary storage
- ğŸ§ª **Comprehensive error handling**: Clear error messages with detailed debugging information

## Installation

### Install the required packages

```bash
$ pip install -r requirements.txt
```

### Setup the environment variables

```bash
$ cp .env.example .env
```

Set your environment variables in the `.env` file. Like `OPENROUTER_API_KEY` value.

## Run the FastAPI server (Development Mode)

```bash
$ uvicorn src.main:app --reload
```